%% graphmatching.tex - approximate graph matching
%%
%% Copyright 2014 Jeffrey Finkelstein.
%%
%% This LaTeX markup document is made available under the terms of the Creative
%% Commons Attribution-ShareAlike 4.0 International License,
%% https://creativecommons.org/licenses/by-sa/4.0/.
\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
%% This must come before hyperref.
\usepackage{amsthm}
%% This is strongly recommended by biblatex.
\usepackage[english]{babel}
\usepackage[backend=biber]{biblatex}
\usepackage[T1]{fontenc}
%% This must come before csquotes.
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
%% This is strongly recommended by biblatex.
\usepackage{csquotes}
%% This must come before hyperref.
\usepackage{thmtools}
%% This must come before complexity.
\usepackage{hyperref}
\usepackage{complexity}
\usepackage[firstpage]{draftwatermark}
\usepackage{microtype}
\usepackage{textcomp}

%% Set the amount by which certain characters protrude into the margins.
%%
%% \LoadMicrotypeFile{cmr}
%%
%%     This command forces the built-in protrusion settings for the Computer
%%     Modern Roman (cmr) font family to become available at this point, so
%%     that we can override these settings on the next line. Even though we are
%%     really using the Latin Modern Roman (lmr) fonts, microtype uses the cmr
%%     configuration file.
%%
%% \SetProtrusion
%%
%%     This instructs the microtype package that we are going to modify the
%%     protrusion settings.
%%
%% [load=lmr-T1]
%%
%%     Loads the Type 1 (T1) encoding of the lmr font family, thereby setting
%%     the default protrusion values for all the characters. This is only
%%     possible after the \LoadMicrotypeFile{cmr} command (microtype
%%     essentially considers lmr to be an alias for cmr).
%%
%% {encoding=T1, family=lmr}
%%
%%     Indicates that we are going to modify the protrusion values for the T1
%%     encoding of the lmr font family.
%%
%% \textquotedblright = {,1000} (and similar commands)
%%
%%     Force the character given by \textquotedblright to have default
%%     protrusion on the left margin (given by an empty string before the
%%     comma) and full protrusion (that is, protrusion value 1000) on the right
%%     margin.
\LoadMicrotypeFile{cmr}
\SetProtrusion
    [load=lmr-T1]
    {encoding=T1, family=lmr}
    {
      \textquotedblright = {,1000},
      \textquotedblleft = {1000,},
      {'} = {,1000},
      {,} = {,1000},
      {:} = {,1000},
      {;} = {,1000},
      {.} = {,1000}
    }

%% Set the ``work-in-progress'' watermark for the first page.
\SetWatermarkLightness{0.9}
\SetWatermarkText{Work-in-progress}
\SetWatermarkFontSize{3.5cm}

%% Set the title and author of the PDF file.
\hypersetup{pdftitle={Approximate graph matching}, pdfauthor={Jeffrey Finkelstein}}

%% Declare the bibliography file.
\addbibresource{graphmatching.bib}

%% Declare theorem-like environments.
\declaretheorem[numberwithin=section]{theorem}
\declaretheorem[numberlike=theorem]{corollary}
\declaretheorem[numberlike=theorem, style=definition]{definition}

%% Custom commands are declared here.
\newcommand{\email}[1]{\textlangle\href{mailto:#1}{\nolinkurl{#1}}\textrangle}
\newcommand{\todo}[1]{\textbf{TODO #1}}
\newcommand{\1}{\mathbf{1}}
\newcommand{\MD}{\textsc{Minimum Disagreement}}
\renewcommand{\MA}{\textsc{Maximum Agreement}}
\newcommand{\RMD}{\textsc{Relaxed Minimum Disagreement}}
\newcommand{\RMA}{\textsc{Relaxed Maximum Agreement}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\agr}{agr}

%% Redefine the footnote environment so it has no reference and no number.
\long\def\symbolfootnote#1{\begingroup%
\def\thefootnote{\fnsymbol{footnote}}\footnotetext{#1}\endgroup}

%% Define the author, title, and date for the document.
\author{Jeffrey~Finkelstein\\ Computer Science Department, Boston University}
\title{Approximate graph matching}

\begin{document}

\maketitle

\symbolfootnote{%
  Copyright 2014 Jeffrey~Finkelstein \email{jeffreyf@bu.edu}.

  This document is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License, which is available at \mbox{\url{https://creativecommons.org/licenses/by-sa/4.0/}}.
  The \LaTeX{} markup that generated this document can be downloaded from its website at \mbox{\url{https://github.com/jfinkels/graphmatching}}.
  The markup is distributed under the same license.
}

%% Document content goes here.

\section{Definitions of graph matching problems}

Unless otherwise specified, the norm of a matrix $\|M\|$ is the Frobenius norm, defined by $\|M\| = \sqrt{\sum_{i, j} M_{ij}^2}$.
%We also use the entrywise $\ell_1$ norm, $\|M\|_1$, defined by $\|M\|_1 = \sum_{i, j} M_{ij}$.
The all ones vector is denoted $\mathbf{1}$ and the all zeros vector is denoted $\mathbf{0}$.
The all ones matrix is denoted $J$ and the all zeros matrix is denoted $O$.
For two matrices $M$ and $N$, entrywise inequality is denoted $M \geq N$.

Suppose $A$ and $B$ are the adjacency matrices of two undirected graphs on $n$ vertices.
The two graphs are \emph{isomorphic} if there is a permutation matrix $P$ such that $PA = BP$.
The \emph{graph isomorphism problem} is the problem of determining whether such a permutation exists, given $A$ and $B$.
The natural optimization problem corresponding to that decision problem is called the \emph{graph matching problem} and can be expressed as
\begin{align*}
  \text{minimize } & \|PA - BP\|^2 \\
  \text{subject to } & P \1 = \1 \\
  & \1^T P = \1^T \\
  & P \in \{0, 1\}^{n \times n}.
\end{align*}
Since
\begin{align}\label{eq:trace}
  \|PA - BP\|^2 & = \|PA\|^2 + \|BP\|^2 - 2 \langle PA, BP \rangle \nonumber \\
  & = \|PA\|^2 + \|BP\|^2 - 2 \tr(AP^TBP) \nonumber \\
  & = \|A\|^2 + \|B\|^2 - 2 \tr(AP^TBP),
\end{align}
and since $\|A\|$ and $\|B\|$ are constants with respect to the variable $P$, an equivalent formulation of the graph matching problem is
\begin{align*}
  \text{maximize } & \tr(AP^TBP) \\
  \text{subject to } & P \1 = \1 \\
  & \1^T P = \1^T \\
  & P \in \{0, 1\}^{n \times n}.
\end{align*}
A solution to the graph matching problem (in either of these two formulations) is a permutation matrix $P$ that witnesses an isomorphism between the graphs whose adjacency matrices are $A$ and $B$.

Relaxing the constraint ``$P \in \{0, 1\}^{n \times n}$'' to the constraint ``$P \geq O$'', in other words, allowing $P$ to be a doubly stochastic instead of a permutation matrix, yields the \emph{relaxed graph matching problem}.
However, when $P$ is a doubly stochastic matrix, \autoref{eq:trace} does not necessarily hold.
Hence the two formulations of the relaxed graph matching problem corresponding to the two formulations of the graph matching problem are not necessarily equivalent.
For this reason, we give each formulation a different name.

The \emph{convex relaxed graph matching problem} is
\begin{align*}
  \text{minimize } & \|DA - BD\|^2 \\
  \text{subject to } & D \1 = \1 \\
  & \1^T D = \1^T \\
  & D \geq O,
\end{align*}
and the \emph{indefinite relaxed graph matching problem} is
\begin{align*}
  \text{maximize } & \tr(AD^TBD) \\
  \text{subject to } & D \1 = \1 \\
  & \1^T D = \1^T \\
  & D \geq O.
\end{align*}

\section{Complexity of graph matching problems}

In this section, we have renamed the two formulations of the graph matching problem to \MD{} and \MA{}.

Let's express these problems as optimization problems.
\begin{definition}[\MD]
  \mbox{}

  \begin{tabular}{r p{9.3cm}}
    Instance: & adjacency matrices $A$ and $B$ of two undirected graphs on $n$ vertices. \\
    Solution: & $n \times n$ Boolean matrix $P$, subject to the constraints $P^T \1 = \1^T P = \1$. \\
    Measure: & $\|PA - BP\|^2$. \\
    Type: & minimization.
  \end{tabular}
\end{definition}

\begin{definition}[\MA]
  \mbox{}

  \begin{tabular}{r p{9.3cm}}
    Instance: & adjacency matrices $A$ and $B$ of two undirected graphs on $n$ vertices. \\
    Solution: & $n \times n$ Boolean matrix $P$, subject to the constraints $P^T \1 = \1^T P = \1$. \\
    Measure: & $\tr(AP^TBP)$. \\
    Type: & maximization.
  \end{tabular}
\end{definition}

\begin{definition}[\RMD]
  \mbox{}

  \begin{tabular}{r p{9.3cm}}
    Instance: & adjacency matrices $A$ and $B$ of two undirected graphs on $n$ vertices. \\
    Solution: & $n \times n$ nonnegative rational matrix $D$, subject to the constraints $D^T \1 = \1^T D = \1$. \\
    Measure: & $\|DA - BD\|^2$. \\
    Type: & minimization.
  \end{tabular}
\end{definition}

\begin{definition}[\RMA]
  \mbox{}

  \begin{tabular}{r p{9.3cm}}
    Instance: & adjacency matrices $A$ and $B$ of two undirected graphs on $n$ vertices. \\
    Solution: & $n \times n$ nonnegative rational matrix $D$, subject to the constraints $D^T \1 = \1^T D = \1$. \\
    Measure: & $\tr(AD^TBD)$. \\
    Type: & maximization.
  \end{tabular}
\end{definition}

As stated in the previous section, \MD{} and \MA{} are equivalent.
\begin{theorem}
  \MD{} and \MA{} are equivalent under \todo{the strictest possible approximation-preserving} reductions.
\end{theorem}

Here is a summary of the complexity of solving these optimization problems exactly, and the complexity of solving them approximately.
\begin{itemize}
\item
  \MA{} is a special case of \textsc{Quadratic Assignment}, for which computing an exact solution is $\NP$-complete.
  However, computing an exact solution to \MA{} is not known to be $\NP$-complete and not known to be in $\P$.
  In other words, \MA{} is in $\NPO$, but not in $\PO$ unless $\P = \NP$.
  \todo{Computing an approximate solution?}
\item \MD{} is equivalent to \MA{}, so it is in $\NPO$, but not in $\PO$ unless $\P = \NP$.
\item
  \RMD{} is a special case of the \textsc{Convex Quadratic Programming} problem, for which computing an exact solution can be done in polynomial time \autocite{gl90}.
  In other words, \RMD{} is in $\PO$.
  \todo{Is it in $\NNCO$?
  Approximable in $\NC$?}
\item
  \RMA{} is a special case of \textsc{Quadratic Programming}, for which computing an exact solution is $\NP$-complete.
  However, there seems to be a fully polynomial time approximation scheme for \RMA{} \autocite{v14}.
  In other words, \RMA{} is in $\FPTAS$ (I believe).
  \todo{Can this approximation scheme be parallelized, for example, by choosing a polynomial number of equally spaced starting points at each iteration?
  For example, see \url{http://arxiv.org/abs/1404.2644}.
  In other words, is the problem in $\FNCAS$?
  Also, see ``Approximation algorithms for quadratic programming'', by Fu, Luo, and Ye (1996).}
\end{itemize}

Much of the current research seems to involve computing a relaxed graph matching (using one of the two formulations), then projecting that doubly stochastic matrix onto a permutation matrix in order to get a graph matching.
In \autocite{l14}, the authors prove that when doing this, it is best to solve the indefinite relaxed graph matching problem instead of the convex relaxed graph matching problem (that is, \RMA{} instead of \RMD{}), because the former is almost always right and the latter almost always wrong.
Still, under certain conditions, solving the convex relaxed graph matching problem can yield the correct permutation matrix \autocite{abk14, fs14}.
\autocite{kmgg14} seems to be the only work simply finding a relaxed graph matching without projecting that doubly stochastic matrix back to a permutation matrix (they are really only finding a relaxed graph matching between a single graph and itself, but it should be possible, using \autocite{gkms14}, to enforce that when running such an algorithm on the disjoint union of two graphs $A$ and $B$, the solution matches some vertices of $A$ with some vertices of $B$).

\section{Amplifying disagreements}

One of our goals is to find a graph operation that, when applied to graphs that are nearly isomorphic, makes the graphs less isomorphic.

Suppose $G$ and $H$ are undirected, unweighted, nonempty graphs on $n$ vertices with adjacency matrices $A$ and $B$, respectively.
Suppose $\pi$ is a bijection from $V(G)$ to $V(H)$ and $P$ is its corresponding permutation matrix.
For each permutation $\pi$, the \emph{agreement between $G$ and $H$ with respect to $\pi$}, denoted $\agr_\pi(G, H)$, is defined by
\begin{equation*}
  \agr_\pi(G, H) = \frac{\tr(AP^TBP)}{\max(\|A\|^2, \|B\|^2)}.
\end{equation*}
In other words, the agreement between $G$ and $H$ is the ratio of the number of edges correctly matched by $\pi$ to the total number of edges (in \autocite{owwz14}, the agreement is defined equivalently in these graph theoretic terms instead of our linear algebraic terms).
The \emph{agreeability between $G$ and $H$}, denoted $\agr(G, H)$, is defined by
\begin{equation*}
  \agr(G, H) = \max_{\pi \in S_n} \agr_\pi(G, H).
\end{equation*}
When $G$ and $H$ admit a better matching, $\agr(G, H)$ increases.
The graphs $G$ and $H$ are isomorphic exactly when $\agr(G, H) = 1$.

Now we hope to find a graph operation $\star$ such that $\agr(G \star X, H \star Y) < \agr(G, H)$ for some graphs $X$ and $Y$.
One initial attempt is the tensor product, denoted $\otimes$.
A second attempt may be graph powering; something more complicated like the zig-zag product might come later.

\begin{definition}[Tensor products]
  \mbox{}
  \begin{itemize}
  \item
    If $A$ and $B$ are $n \times n$ matrices, then the \emph{tensor product of $A$ and $B$}, denoted $A \otimes B$, is an $n^2 \times n^2$ matrix defined as follows.
    Entry $(i, j, i', j')$ of $A \otimes B$ is $a_{i, j} b_{i', j'}$.
  \item If $G$ and $H$ are graphs with adjacency matrices $A$ and $B$, respectively, then the \emph{tensor product of $G$ and $H$}, denoted $G \otimes H$, is the graph whose adjacency matrix is $A \otimes B$.
  \item If $\pi$ and $\tau$ are permutations in $S_n$, then the \emph{tensor product of $\pi$ and $\tau$}, denoted $\pi \otimes \tau$, are permutations in $S_{n^2}$ defined by $(\pi \otimes \tau)(i, j) = (\pi(i), \tau(j))$.
  \end{itemize}
\end{definition}

\begin{theorem}
  If $\pi$ and $\tau$ are permutations with corresponding permutation matrices $P$ and $Q$, respectively, then $\pi \otimes \tau$ is a permutation with corresponding permutation $P \otimes Q$.
\end{theorem}

\begin{theorem}
  Suppose $A$ and $B$ are $n \times n$ Boolean matrices.
  If $A \otimes A = B \otimes B$, then $A = B$.
\end{theorem}
\begin{proof}
  We prove the contrapositive.
  Suppose $A \neq B$.
  Assume without loss of generality that the top left entry of $A$ is $0$ and the top left entry of $B$ is $1$.
  Then the top left entry of $A \otimes A$ is a $0$ and the top left entry of $B \otimes B$ is $1$.
  Therefore $A \otimes A \neq B \otimes B$.
\end{proof}

\begin{theorem}
  For any undirected, unweighted, nonempty graphs $G$ and $H$ on $n$ vertices, and for any bijection $\pi$ from $V(G)$ to $V(H)$,
  \begin{equation*}
    \agr_{\pi \otimes \pi}(G \otimes G, H \otimes H) = \agr_\pi(G, H)^2.
  \end{equation*}
\end{theorem}
\begin{proof}
  This follows directly from the properties of the tensor product.
  We consider the numerator and the denominator of the agreement separately.
  Suppose $A$ and $B$ are the adjacency matrices of $G$ and $H$, respectively, and suppose $P$ is the permutation matrix corresponding to $\pi$.
  For the numerator,
  \begin{align*}
    \tr((A \otimes A)(P \otimes P)^T(B \otimes B)(P \otimes P)) & = \tr((A \otimes A)(P^T \otimes P^T)(B \otimes B)(P \otimes P)) \\
    & = \tr((AP^T \otimes AP^T)(BP \otimes BP)) \\
    & = \tr(AP^TBP \otimes AP^TBP) \\
    & = \tr(AP^TBP)^2.
  \end{align*}
  For the denominator,
  \begin{equation*}
    \max(\|A \otimes A\|^2, \|B \otimes B\|^2) = \max((\|A\|^2)^2, (\|B\|^2)^2) = \max(\|A\|^2, \|B\|^2)^2.
  \end{equation*}
  Combine these two equalities with the definition of the agreement between $G$ and $H$ to produce the equality in the statement of the theorem.
\end{proof}

The next corollary follows from the previous theorem by induction on $\ell$.

\begin{corollary}
  Suppose $\ell$ is a positive integer, $G$ and $H$ are undirected, unweighted, nonempty graphs on $n$ vertices, and $\pi$ is a bijection from $V(G)$ to $V(H)$.

  Let $\mathbf{G} = \bigotimes_{i = 1}^\ell G$, let $\mathbf{H} = \bigotimes_{i = 1}^\ell H$, and let $\Pi = \bigotimes_{i = 1}^\ell \pi$.
  Now
  \begin{equation*}
    \agr_{\Pi}(\mathbf{G}, \mathbf{H}) = \agr_\pi(G, H)^\ell.
  \end{equation*}
\end{corollary}

%% Completeness
This corollary provides a lower bound for the agreement of the larger graphs $\mathbf{G}$ and $\mathbf{H}$ given a lower bound for the agreement of the original graphs $G$ and $H$, though the bound is rather unhelpful because it decreases rapidly.
However, it does show that the tensor product, when used in this way, preserves isomorphism.

%% \begin{theorem}
%%   For any square matrices $P$, $A$, and $B$, if $PA = BP$ then $(P \otimes P)(A \otimes A) = (B \otimes B)(P \otimes P)$.
%% \end{theorem}
%% \begin{proof}
%%   By the mixed-product property of the tensor product,
%%   \begin{equation*}
%%     (P \otimes P)(A \otimes A) = PA \otimes PA = BP \otimes BP = (B \otimes B)(P \otimes P).
%%   \end{equation*}
%% \end{proof}

\begin{theorem}
  Suppose $\ell$ is a positive integer and $G$ and $H$ are undirected, unweighted, nonempty graphs $G$ and $H$ on $n$ vertices.
  Let $\mathbf{G} = \bigotimes_{i = 1}^\ell G$ and $\mathbf{H} = \bigotimes_{i = 1}^\ell H$.
  \begin{equation*}
    \agr(G, H)^\ell \leq \agr(\mathbf{G}, \mathbf{H}),
  \end{equation*}
  with equality when $G$ is isomorphic to $H$.
  In particular, for any $\epsilon \in [0, 1]$, if $\epsilon \leq \agr(G, H)$ then $\epsilon^\ell \leq \agr(\mathbf{G}, \mathbf{H})$.
\end{theorem}
\begin{proof}
  Let $\pi$ be the bijection that maximizes $\agr_\pi(G, H)$ and let $\Pi = \bigotimes_{i = 1}^\ell \pi$.
  By the previous corollary,
  \begin{equation*}
    \agr(G, H)^\ell = \agr_\pi(G, H)^\ell = \agr_\Pi(\mathbf{G}, \mathbf{H}).
  \end{equation*}
  Since $\Pi$ is just one bijection out of all possible bijections between the vertices of $\mathbf{G}$ and $\mathbf{H}$,
  \begin{equation*}
    \agr_\Pi(\mathbf{G}, \mathbf{H}) \leq \max_\tau \agr_\tau(\mathbf{G}, \mathbf{H}) = \agr(\mathbf{G}, \mathbf{H}).
  \end{equation*}
  Combine these equalities and inequalities to produce the inequality in the statement of the theorem.
  If $G$ and $H$ are isomorphic, then $\agr(G, H)^\ell = 1^\ell = 1$, so
  \begin{equation*}
    1 = \agr(G, H)^\ell \leq \agr(\mathbf{G}, \mathbf{H}) \leq 1.
  \end{equation*}

  Finally, if $\epsilon \leq \agr(G, H)$, then $\epsilon^\ell \leq \agr(G, H)^\ell \leq \agr(\mathbf{G}, \mathbf{H})$.
\end{proof}

%% Soundness
What we would like is an upper bound for the agreement of the larger graphs $\mathbf{G}$ and $\mathbf{H}$ given an upper bound for the agreement of the original graphs $G$ and $H$.
Something like if $\agr(G, H) < \epsilon$, then $\agr(\mathbf{G}, \mathbf{H}) < \epsilon' < \epsilon$.
\todo{How to show this?}

\todo{
  Is it true that if $\hat{P}(A \otimes A) = (B \otimes B)\hat{P}$ then $\hat{P} = P \otimes P$ for some permutation matrix $P$?
  If so, then we can conclude that $PA = BP$.
  In \autocite{owwz14}, the authors claim, citing a complicated \oldstylenums{1971} math paper, that if $G \otimes G$ is isomorphic to $H \otimes H$, then $G$ is isomorphic to $H$.
}

\todo{Is it easier to show that some graph product increases disagreement instead of showing that it decreases agreement?}

\todo{What if we use the relaxed versions of the problem here?}

%% Print the bibliography section here.
\printbibliography

\end{document}
